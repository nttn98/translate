<!DOCTYPE html>
<html lang="vi">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vietnamese to English Translator</title>
    <link rel="stylesheet" href="/static/style.css" />
  </head>
  <body>
    <div class="container">
      <h1>Vietnamese to English Translator</h1>

      <div class="status-bar" id="status">Ready</div>

      <div class="section">
        <div class="section-header">
          <span class="section-title">Vietnamese Input</span>
          <button
            class="btn btn-primary"
            id="voiceBtn"
            onclick="handleVoiceInput()"
          >
            üé§ Voice Input
          </button>
        </div>
        <textarea
          id="inputText"
          placeholder="Type Vietnamese here..."
        ></textarea>
      </div>

      <div class="output-section">
        <div class="section-header">
          <span class="section-title">English Translation</span>
        </div>
        <div class="output-text" id="outputText">
          Translation will appear here...
        </div>
        <div class="button-group">
          <button class="btn btn-success" id="speakBtn" onclick="handleSpeak()">
            üîä Speak
          </button>
          <button class="btn btn-danger" onclick="handleStop()">‚èπÔ∏è Stop</button>
        </div>
      </div>

      <div class="settings">
        <h3>Settings</h3>

        <div class="setting-item">
          <label>Speech Speed: <span id="speedValue">1.0x</span></label>
          <input
            type="range"
            id="speedSlider"
            min="0.5"
            max="2"
            step="0.1"
            value="1.0"
            oninput="updateSpeed(this.value)"
          />
        </div>

        <label class="checkbox-label">
          <input type="checkbox" id="autoSpeak" checked />
          Auto-speak after translation
        </label>

        <label class="checkbox-label">
          <input type="checkbox" id="continuous" checked />
          Continuous mode (only new text)
        </label>
      </div>
    </div>

    <script>
      // -------------------------
      // State (typing/TTS)
      // -------------------------
      let typingTimer;
      let lastText = "";
      let lastPosition = 0;
      let isSpeaking = false;

      function updateStatus(status) {
        const el = document.getElementById("status");
        if (el) el.textContent = status;
        console.log("[STATUS]", status);
      }

      function updateSpeed(value) {
        document.getElementById("speedValue").textContent =
          parseFloat(value).toFixed(1) + "x";
      }

      // Typing debounce (unchanged)
      document.getElementById("inputText").addEventListener("input", (e) => {
        const text = e.target.value;
        clearTimeout(typingTimer);

        if (text.trim()) {
          updateStatus("Typing...");
          typingTimer = setTimeout(() => {
            translateText(text);
          }, 1000);
        } else {
          document.getElementById("outputText").textContent =
            "Translation will appear here...";
          lastText = "";
          lastPosition = 0;
          updateStatus("Ready");
        }
      });

      // -------------------------
      // Translate (unchanged)
      // -------------------------
      async function translateText(text) {
        if (!text.trim()) return;

        updateStatus("Translating...");

        try {
          const response = await fetch("/translate", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: text }),
          });

          const data = await response.json();

          if (data.translation) {
            document.getElementById("outputText").textContent =
              data.translation;
            lastText = data.translation;
            updateStatus("Ready");

            if (document.getElementById("autoSpeak").checked) {
              setTimeout(() => speakText(data.translation), 300);
            }
          } else {
            document.getElementById("outputText").textContent =
              "Translation failed: " + (data.error || "Unknown error");
            updateStatus("Error");
          }
        } catch (error) {
          console.error("Translation error:", error);
          document.getElementById("outputText").textContent =
            "Translation failed. Please check your connection.";
          updateStatus("Error");
        }
      }

      // -------------------------
      // Text-to-Speech (unchanged)
      // -------------------------
      function speakText(text) {
        if (!text || text === "Translation will appear here...") return;

        let textToSpeak = text;

        if (document.getElementById("continuous").checked && lastPosition > 0) {
          const previousPart = lastText.substring(0, lastPosition);
          if (text.indexOf(previousPart) === 0) {
            textToSpeak = text.substring(lastPosition).trim();
            if (!textToSpeak) return;
          }
        }

        window.speechSynthesis.cancel();

        const utterance = new SpeechSynthesisUtterance(textToSpeak);
        utterance.lang = "en-US";
        utterance.rate = parseFloat(
          document.getElementById("speedSlider").value
        );

        utterance.onstart = () => {
          isSpeaking = true;
          updateStatus("Speaking...");
          document.getElementById("speakBtn").className = "btn btn-speaking";
        };

        utterance.onend = () => {
          isSpeaking = false;
          updateStatus("Ready");
          document.getElementById("speakBtn").className = "btn btn-success";
          lastPosition = text.length;
        };

        utterance.onerror = () => {
          isSpeaking = false;
          updateStatus("Ready");
          document.getElementById("speakBtn").className = "btn btn-success";
        };

        window.speechSynthesis.speak(utterance);
      }

      window.handleSpeak = function () {
        if (lastText) {
          lastPosition = 0;
          speakText(lastText);
        }
      };

      window.handleStop = function () {
        window.speechSynthesis.cancel();
        isSpeaking = false;
        updateStatus("Ready");
        document.getElementById("speakBtn").className = "btn btn-success";
      };

      // -------------------------
      // Minimal safe SpeechRecognition
      // - create fresh instance each start
      // - request mic permission first
      // - continuous = false (single-utterance)
      // -------------------------
      let recognition = null;
      let isListening = false;

      function makeRecognition() {
        if (
          !(
            "webkitSpeechRecognition" in window || "SpeechRecognition" in window
          )
        ) {
          console.warn("SpeechRecognition not supported in this browser.");
          recognition = null;
          return null;
        }
        const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
        try {
          const rec = new SR();
          rec.lang = "vi-VN";
          rec.continuous = false;
          rec.interimResults = false;
          rec.maxAlternatives = 1;

          rec.onstart = () => {
            isListening = true;
            updateStatus("Listening...");
            const vb = document.getElementById("voiceBtn");
            if (vb) {
              vb.className = "btn btn-listening";
              vb.textContent = "üé§ Listening...";
            }
            console.log("SpeechRecognition.onstart");
          };

          rec.onresult = (evt) => {
            const transcript = Array.from(evt.results)
              .slice(evt.resultIndex)
              .map((r) => r[0].transcript)
              .join("");
            console.log("SpeechRecognition.onresult:", transcript);
            const inputEl = document.getElementById("inputText");
            if (inputEl) {
              inputEl.value = transcript;
              // keep existing typing flow
              inputEl.dispatchEvent(new Event("input", { bubbles: true }));
            } else {
              if (typeof translateText === "function")
                translateText(transcript);
            }
          };

          rec.onerror = (e) => {
            try {
              // e c√≥ th·ªÉ l√† SpeechRecognitionErrorEvent ‚Äî in chi ti·∫øt
              console.error("SpeechRecognition.onerror event:", e);
              console.dir(e); // show full object properties in console

              // in c√°c thu·ªôc t√≠nh th∆∞·ªùng g·∫∑p
              const err =
                e && e.error ? e.error : e && e.type ? e.type : "unknown";
              console.log(">> error:", err);
              console.log(">> isTrusted:", e && e.isTrusted);
              console.log(">> message:", e && e.message);
              console.log(">> timeStamp:", e && e.timeStamp);
              console.log(">> navigator.onLine:", navigator.onLine);

              // show user-visible status
              updateStatus("Error: " + err);

              // UI reset
              isListening = false;
              const vb = document.getElementById("voiceBtn");
              if (vb) {
                vb.className = "btn btn-primary";
                vb.textContent = "üé§ Voice Input";
              }

              // Suggest actions for common errors
              if (err === "not-allowed" || err === "service-not-allowed") {
                alert(
                  "Microphone permission denied ‚Äî b·∫≠t microphone cho trang n√†y trong Settings."
                );
              } else if (err === "network") {
                // network: backend Web Speech cloud error (not your network connectivity necessarily)
                console.warn(
                  "SpeechRecognition network error: backend speech service may be unreachable."
                );
                alert(
                  "Speech service network error. Th·ª≠ t·∫Øt VPN/proxy, ƒë·ªïi m·∫°ng, ho·∫∑c d√πng Incognito. N·∫øu mu·ªën, t√¥i c√≥ th·ªÉ b·∫≠t fallback MediaRecorder."
                );
              }
            } catch (logErr) {
              console.error("Error while logging speech error:", logErr);
            }
          };

          rec.onend = () => {
            console.log("SpeechRecognition.onend");
            isListening = false;
            updateStatus("Ready");
            const vb = document.getElementById("voiceBtn");
            if (vb) {
              vb.className = "btn btn-primary";
              vb.textContent = "üé§ Voice Input";
            }
          };

          rec.onaudioend = () => {
            console.log("SpeechRecognition.onaudioend (audio capture ended)");
          };

          return rec;
        } catch (err) {
          console.error("makeRecognition error:", err);
          recognition = null;
          return null;
        }
      }

      async function handleVoiceInput() {
        // secure context check
        if (
          !(
            location.protocol === "https:" ||
            location.hostname === "localhost" ||
            location.hostname === "127.0.0.1"
          )
        ) {
          alert(
            "SpeechRecognition requires HTTPS or http://localhost. Open via https or localhost."
          );
          return;
        }

        // if currently listening, stop
        if (isListening && recognition) {
          try {
            recognition.stop();
          } catch (e) {
            console.warn("recognition.stop error:", e);
          }
          return;
        }

        // request mic permission first
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          stream.getTracks().forEach((t) => t.stop()); // we only needed permission
        } catch (err) {
          console.warn("getUserMedia permission error:", err);
          alert(
            "Unable to access microphone. Please allow microphone permission for this page."
          );
          return;
        }

        // create fresh instance and start
        recognition = makeRecognition();
        if (!recognition) {
          alert(
            "SpeechRecognition not supported in this browser. Use Chrome or Edge."
          );
          return;
        }

        try {
          recognition.start();
        } catch (err) {
          console.error("recognition.start() failed:", err);
          try {
            recognition = makeRecognition();
            if (recognition) recognition.start();
          } catch (err2) {
            console.error("Retry recognition.start failed:", err2);
            alert(
              "Could not start voice recognition: " + (err2.message || err2)
            );
          }
        }
      }

      window.handleVoiceInput = handleVoiceInput;
    </script>
  </body>
</html>
